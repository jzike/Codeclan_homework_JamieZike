library(textdata)
pride_book <- prideprejudice
sense_book <- sensesensibility
tibble(
id = 1:length(pride_book),
text = pride_book
)
?unnest_tokens
pride_book <- tibble(
id = 1:length(pride_book),
text = pride_book
) %>%
unnest_tokens(words, text)
sense_book <- tibble(
id = 1:length(sense_book),
text = sense_book
) %>%
unnest_tokens(words, text)
View(pride_book)
pride_book %>%
count(text, sort = TRUE)
pride_book %>%
count(words, sort = TRUE)
sense_book %>%
count(words, sort = TRUE)
pride_book %>%
count(words, sort = TRUE)
sense_book %>%
count(words, sort = TRUE)
pride_book %>%
anti_join(stop_words) %>%
count(words, sort = TRUE)
stop_words
?anti_join
pride_book %>%
anti_join(stop_words, by = c(words, word)) %>%
count(words, sort = TRUE)
pride_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
count(words, sort = TRUE)
pride_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
count(words, sort = TRUE)
sense_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
count(words, sort = TRUE)
get_sentiments("afinn")
get_sentiments("bing") %>%
count(sentiment)
get_sentiments("loughran") %>%
count(sentiment)
get_sentiments("nrc") %>%
count(sentiment)
pride_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
inner_join(get_sentiments("nrc"))
get_sentiments("nrc")
pride_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
inner_join(get_sentiments("nrc"), by = c("words" = "word"))
pride_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
inner_join(get_sentiments("nrc"), by = c("words" = "word")) %>%
group_by(sentiment, word) %>%
slice_max(n = 10)
pride_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
inner_join(get_sentiments("nrc"), by = c("words" = "word")) %>%
group_by(sentiment, words) %>%
slice_max(n = 10)
?slice_max
pride_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
inner_join(get_sentiments("nrc"), by = c("words" = "word")) %>%
group_by(sentiment, words) %>%
count(words, sort = TRUE) %>%
slice_max(n = 10)
pride_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
inner_join(get_sentiments("nrc"), by = c("words" = "word")) %>%
group_by(sentiment, words) %>%
count(words, sort = TRUE)
pride_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
inner_join(get_sentiments("nrc"), by = c("words" = "word")) %>%
group_by(sentiment, words) %>%
count(words, sort = TRUE) %>%
slice_max(order_by = n, n = 10)
pride_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
inner_join(get_sentiments("nrc"), by = c("words" = "word")) %>%
group_by(sentiment, words) %>%
slice_max(words, n = 10)
pride_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
inner_join(get_sentiments("nrc"), by = c("words" = "word")) %>%
count(sentiment, words, sort = TRUE) %>%
slice(10)
pride_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
inner_join(get_sentiments("nrc"), by = c("words" = "word")) %>%
count(sentiment, words, sort = TRUE)
pride_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
inner_join(get_sentiments("nrc"), by = c("words" = "word")) %>%
group_by(sentiment, words) %>%
summarise(count = n())
pride_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
inner_join(get_sentiments("bing"), by = c("words" = "word")) %>%
group_by(sentiment, words) %>%
summarise(count = n())
pride_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
inner_join(get_sentiments("bing"), by = c("words" = "word")) %>%
count(sentiment, words, sort = TRUE)
pride_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
inner_join(get_sentiments("bing"), by = c("words" = "word")) %>%
filter(words != "miss") %>%
count(sentiment, words, sort = TRUE)
sense_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
inner_join(get_sentiments("bing"), by = c("words" = "word")) %>%
count(sentiment, words, sort = TRUE)
sense_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
inner_join(get_sentiments("bing"), by = c("words" = "word")) %>%
filter(words != "miss") %>%
count(sentiment, words, sort = TRUE)
pride_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
inner_join(get_sentiments("bing"), by = c("words" = "word")) %>%
filter(words != "miss") %>% #take out miss b/c its used v frequently as a title and will impact results
count(sentiment, words, sort = TRUE)
sense_book %>%
anti_join(stop_words, by = c("words" = "word")) %>%
inner_join(get_sentiments("bing"), by = c("words" = "word")) %>%
filter(words != "miss") %>% #take out miss b/c its used v frequently as a title and will impact results
count(sentiment, words, sort = TRUE)
View(pride_book)
pride_book %>%
mutate(title = "pride and prejudice")
pride_book %>%
mutate(title = "pride and prejudice", .before = id)
sense_book <- sense_book %>%
mutate(title = "sense and sensibility", .before = id)
pride_book <- pride_book %>%
mutate(title = "pride and prejudice", .before = id)
pride_book %>%
bind_rows(sense_book)
books <- pride_book %>%
bind_rows(sense_book)
books %>%
inner_join(get_sentiments("afinn"))
books %>%
inner_join(get_sentiments("afinn"), by c(words = word))
books %>%
inner_join(get_sentiments("afinn"), by = c(words = word))
books %>%
inner_join(get_sentiments("afinn"), by = c("words" = "word"))
book_sentiments <- books %>%
inner_join(get_sentiments("afinn"), by = c("words" = "word"))
View(book_sentiments)
View(pride_book)
book_sentiments %>%
group_by(title, id)
book_sentiments %>%
group_by(title, id) %>%
summarise(mean_sentiment = mean(value))
book_sentiments %>%
group_by(title, id) %>%
summarise(mean_sentiment = mean(value)) %>%
filter(title == "sense and sensibility")
book_sentiments %>%
group_by(title, id) %>%
summarise(mean_sentiment = mean(value)) %>%
ggplot(aes(x = id,
y = mean_sentiment,
colour = title)) +
geom_point() +
geom_line(group = title)
book_sentiments %>%
group_by(title, id) %>%
summarise(mean_sentiment = mean(value)) %>%
ggplot(aes(x = id,
y = mean_sentiment,
colour = title)) +
geom_point()
book_sentiments %>%
group_by(title, id) %>%
summarise(mean_sentiment = mean(value)) %>%
ggplot(aes(x = id,
y = mean_sentiment,
colour = title)) +
geom_point(alpha = 0.3) +
geom_smooth()
book_sentiments %>%
group_by(title, id) %>%
summarise(mean_sentiment = mean(value)) %>%
ggplot(aes(x = id,
y = mean_sentiment,
colour = title)) +
geom_point(alpha = 0.2) +
geom_smooth()
book_sentiments %>%
group_by(title, id) %>%
summarise(mean_sentiment = mean(value)) %>%
ggplot(aes(x = id,
y = mean_sentiment,
colour = title)) +
#geom_point(alpha = 0.2) +
geom_smooth()
book_sentiments %>%
group_by(title, id) %>%
summarise(mean_sentiment = mean(value)) %>%
ggplot(aes(x = id,
y = mean_sentiment,
colour = title)) +
geom_point(alpha = 0.2) +
geom_smooth()
book_sentiments %>%
group_by(title, id) %>%
summarise(mean_sentiment = mean(value)) %>%
ggplot(aes(x = id,
y = mean_sentiment,
colour = title)) +
#geom_point(alpha = 0.2) +
geom_smooth()
library(tidyverse)
library(modelr)
library(glmulti)
oj_purchases <- read_csv("data/orange_juice.csv") %>% janitor::clean_names()
oj_purchases %>% head()
oj_purchases %>% skimr::skim()
View(oj_purchases)
oj_purchases %>% head()
oj_purchases %>%
mutate(purchase_mm = purchase == "MM", .after = purchase)
oj_purchases <- oj_purchases %>%
mutate(purchase_mm = purchase == "MM", .after = purchase)
head(oj_purchases)
oj_purchases <- oj_purchases %>%
mutate(purchase = purchase == "MM", .after = purchase)
head(oj_purchases)
oj_purchases <- read_csv("data/orange_juice.csv") %>% janitor::clean_names()
oj_purchases <- oj_purchases %>%
mutate(purchase_mm = purchase == "MM") %>%
select(-purchase)
head(oj_purchases)
oj_purchases <- read_csv("data/orange_juice.csv") %>% janitor::clean_names()
oj_purchases <- oj_purchases %>%
mutate(purchase_mm = purchase == "MM", .after = purchase) %>%
select(-purchase)
head(oj_purchases)
oj_purchases %>% distinct(weekof_purchase)
head(oj_purchases)
alias(purchase_mm ~ ., data = oj_purchases)
oj_purchases %>%
select(-c(sale_price_ch, sale_price_mm, list_price_diff,disc_ch, disc_mm, store7)) %>%
alias(purchase_mm ~ ., data = oj_purchases)
oj_purchases %>%
mutate(list_test = list_price_diff == price_diff) %>%
filter(list_test == FALSE)
alias(purchase_mm ~ ., data = oj_purchases)
oj_purchases %>%
select(-c(price_ch, price_mm, disc_ch, disc_mm, sale_price_ch, sale_price_mm,
pct_disc_ch, pct_disc_mm, list_price_diff))
oj_purchases %>%
select(-c(price_ch, price_mm, disc_ch, disc_mm, sale_price_ch, sale_price_mm,
pct_disc_ch, pct_disc_mm, list_price_diff, store7))
oj_purchases %>%
select(-c(price_ch, price_mm, disc_ch, disc_mm, sale_price_ch, sale_price_mm,
pct_disc_ch, pct_disc_mm, list_price_diff, store7, store,
weekof_purchase))
tidy_oj_purchases <- oj_purchases %>%
select(-c(price_ch, price_mm, disc_ch, disc_mm, sale_price_ch, sale_price_mm,
pct_disc_ch, pct_disc_mm, list_price_diff, store7, store,
weekof_purchase))
n_data <- 1:length(oj_purchases)
n_data <- nrow(tidy_oj_purchases)
test_index <- (1:n_data, size = n_data * 0.20)
test_index <- sample(1:n_data, size = n_data * 0.20)
n_data <- nrow(tidy_oj_purchases)
test_index <- sample(1:n_data, size = n_data * 0.20)
test_oj <- slice(tidy_oj_purchases, test_index)
train_oj <- slice(tidy_oj_purchases, -test_index)
train_oj %>%
janitor::tabyl(purchase_mm)
train_oj %>%
janitor::tabyl(purchase_mm)
test_oj %>%
janitor::tabyl(purchase_mm)
glmulti_search_all_mains <- glmulti(
purchase_mm ~ .,
data = train_oj,
level = 1,
method = "h",
crit = "bic",
confsetsize = 10,
plotty = F,
report = T,
fitfunction = "glm",
family = binomial(link = "logit")
)
View(train_oj)
summary(glmulti_search_all_mains)
top <- weightable(glmulti_search_all_mains)
top
glmulti_search_interactions <- glmulti(
purchase_mm ~ store_id + loyal_ch + price_diff,
data = train_oj,
level = 2,
method = "h",
crit = "bic",
confsetsize = 10,
marginality = TRUE,
minsize = 6,
maxsize = 6,
plotty = F,
report = T,
fitfunction = "glm",
family = binomial(link = "logit")
)
weightable(glmulti_search_interactions)
summary(glmulti_search_interactions)
glmulti_search_interactions <- glmulti(
purchase_mm ~ store_id + loyal_ch + price_diff,
data = train_oj,
level = 2,
method = "h",
crit = "bic",
confsetsize = 10,
marginality = TRUE,
minsize = 4,
maxsize = 4,
plotty = F,
report = T,
fitfunction = "glm",
family = binomial(link = "logit")
)
summary(glmulti_search_interactions)
weightable(glmulti_search_interactions)
mod_oj <-
glm(purchase_mm ~ store_id + loyal_ch + price_diff,
data = train_oj,
family = binomial(link = "logit"))
train_oj %>%
add_predictions(model = mod_oj, type = "response")
train_oj %>%
add_predictions(model = mod_oj, type = "response") %>%
mutate(pred_mm = pred >= 0.60)
train_oj_pred <- train_oj %>%
add_predictions(model = mod_oj, type = "response") %>%
mutate(pred_mm = pred >= 0.60)
summary(mod_oj)
oj_purchases %>%
select(-c(price_ch, price_mm, disc_ch, disc_mm, sale_price_ch, sale_price_mm,
pct_disc_ch, pct_disc_mm, list_price_diff, store7, store,
weekof_purchase)) %>%
mutate(store_id = as.factor(store_id))
tidy_oj_purchases <- oj_purchases %>%
select(-c(price_ch, price_mm, disc_ch, disc_mm, sale_price_ch, sale_price_mm,
pct_disc_ch, pct_disc_mm, list_price_diff, store7, store,
weekof_purchase)) %>%
mutate(store_id = as.factor(store_id),
special_ch = as.factor(special_ch),
special_mm = as.factor(special_mm))
View(tidy_oj_purchases)
n_data <- nrow(tidy_oj_purchases)
test_index <- sample(1:n_data, size = n_data * 0.20)
test_oj <- slice(tidy_oj_purchases, test_index)
train_oj <- slice(tidy_oj_purchases, -test_index)
train_oj %>%
janitor::tabyl(purchase_mm)
test_oj %>%
janitor::tabyl(purchase_mm)
n_data <- nrow(tidy_oj_purchases)
test_index <- sample(1:n_data, size = n_data * 0.20)
test_oj <- slice(tidy_oj_purchases, test_index)
train_oj <- slice(tidy_oj_purchases, -test_index)
train_oj %>%
janitor::tabyl(purchase_mm)
test_oj %>%
janitor::tabyl(purchase_mm)
glmulti_search_all_mains <- glmulti(
purchase_mm ~ .,
data = train_oj,
level = 1,
method = "h",
crit = "bic",
confsetsize = 10,
plotty = F,
report = T,
fitfunction = "glm",
family = binomial(link = "logit")
)
summary(glmulti_search_all_mains)
top <- weightable(glmulti_search_all_mains)
top
glmulti_search_interactions <- glmulti(
purchase_mm ~ loyal_ch + price_diff,
data = train_oj,
level = 2,
method = "h",
crit = "bic",
confsetsize = 10,
marginality = TRUE,
minsize = 3,
maxsize = 3,
plotty = F,
report = T,
fitfunction = "glm",
family = binomial(link = "logit")
)
summary(glmulti_search_interactions)
weightable(glmulti_search_interactions)
mod_oj <-
glm(purchase_mm ~ loyal_ch + price_diff,
data = train_oj,
family = binomial(link = "logit"))
train_oj_pred <- train_oj %>%
add_predictions(model = mod_oj, type = "response") %>%
mutate(pred_mm = pred >= 0.60)
summary(mod_oj)
train_oj_pred <- train_oj %>%
add_predictions(model = mod_oj, type = "response")
train_oj %>%
add_predictions(model = mod_oj, type = "response")
train_oj_pred <- train_oj %>%
add_predictions(model = mod_oj, type = "response") %>%
mutate(pred_mm = pred >= 0.50)
View(train_oj_pred)
#check the confusion table
train_oj_pred %>%
tabyl(purchase_mm, pred_mm) %>%
adorn_title()
library(janitor)
#check the confusion table
train_oj_pred %>%
tabyl(purchase_mm, pred_mm) %>%
adorn_title()
test_oj_pred <- test_oj %>%
add_predictions(model = mod_oj, type = "response") %>%
mutate(pred_mm = pred >= 0.50)
#check the confusion table
test_oj_pred %>%
tabyl(purchase_mm, pred_mm) %>%
adorn_title()
auc(mod_oj)
library(pROC)
mod_oj_interaction <-
glm(purchase_mm ~ loyal_ch + price_diff + loyal_ch:price_diff,
data = train_oj,
family = binomial(link = "logit"))
train_oj_pred_interaction <- train_oj %>%
add_predictions(model = mod_oj_interaction, type = "response") %>%
mutate(pred_mm = pred >= 0.50)
#check the confusion table
train_oj_pred %>%
tabyl(purchase_mm, pred_mm) %>%
adorn_title()
train_oj_pred_interaction %>%
tabyl(purchase_mm, pred_mm) %>%
adorn_title()
test_oj_pred
roc_obj_oj <- test_oj_pred %>%
roc(response = purchase_mm, predictor = pred)
ggroc(data = roc_obj_oj,
legacy.axes = TRUE)
ggroc(data = roc_obj_oj,
legacy.axes = TRUE)+
labs(x = "False Positive Rate", y = "True Positive Rate")
auc(roc_obj_oj)
library(tidyverse)
library(modelr)
library(glmulti)
library(janitor)
library(pROC)
oj_purchases <- read_csv("data/orange_juice.csv") %>% janitor::clean_names()
oj_purchases <- oj_purchases %>%
mutate(purchase_mm = purchase == "MM", .after = purchase) %>%
select(-purchase)
tidy_oj_purchases <- oj_purchases %>%
select(-c(price_ch, price_mm, disc_ch, disc_mm, sale_price_ch, sale_price_mm,
pct_disc_ch, pct_disc_mm, list_price_diff, store7, store,
weekof_purchase)) %>%
mutate(store_id = as.factor(store_id),
special_ch = as.factor(special_ch),
special_mm = as.factor(special_mm))
n_data <- nrow(tidy_oj_purchases)
test_index <- sample(1:n_data, size = n_data * 0.20)
test_oj <- slice(tidy_oj_purchases, test_index)
train_oj <- slice(tidy_oj_purchases, -test_index)
train_oj %>%
janitor::tabyl(purchase_mm)
test_oj %>%
janitor::tabyl(purchase_mm)
glmulti_search_all_mains <- glmulti(
purchase_mm ~ .,
data = train_oj,
level = 1,
method = "h",
crit = "bic",
confsetsize = 10,
plotty = F,
report = T,
fitfunction = "glm",
family = binomial(link = "logit")
)
summary(glmulti_search_all_mains)
summary(glmulti_search_all_mains)
